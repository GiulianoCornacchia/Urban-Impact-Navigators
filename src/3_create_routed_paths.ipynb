{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from utils_mobility_demand import load_route_file_in_dict, create_xml_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intervals(N, S):\n",
    "    \n",
    "    # each interval is [a, b)\n",
    "    \n",
    "    interval_size = N // S\n",
    "    intervals = []\n",
    "    for i in range(S):\n",
    "        start = i * interval_size\n",
    "        end = (i + 1) * interval_size - 1 if i < S - 1 else N - 1\n",
    "        intervals.append((start, end+1))\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def save_dict_to_gzipped_json(data, filename):\n",
    "    with gzip.open(filename, 'wt') as gzipped_file:\n",
    "        json.dump(data, gzipped_file)\n",
    "\n",
    "def load_dict_from_gzipped_json(filename):\n",
    "    with gzip.open(filename, 'rt') as gzipped_file:\n",
    "        data = json.load(gzipped_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"milan\"\n",
    "N = 5000\n",
    "njobs = 5\n",
    "\n",
    "w = 1\n",
    "\n",
    "# ----- #\n",
    "\n",
    "demand_file = f\"../data/{city}/mobility_demand/N{N}/dict_mobility_demand_{city}_N{N}.json\"\n",
    "\n",
    "road_network_path = f\"../data/road_networks/sumo_road_network_{city}.net.xml\"\n",
    "\n",
    "# TMP\n",
    "result_folder = f\"../data/{city}/mydua_tmp/\"\n",
    "result_folder_chunks = f\"{result_folder}tmp_mydua_w{str(w).replace('.','p')}/\"\n",
    "\n",
    "print(f\"w={w}\", road_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87014b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = generate_intervals(N, njobs)\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ee8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "processes = []\n",
    "\n",
    "np.random.seed()\n",
    "seed = np.random.randint(0, 1e7)\n",
    "\n",
    "print(f\"Random seed: {seed}\")\n",
    "\n",
    "for interval in intervals:\n",
    "    \n",
    "    options = f\"-c {city} -N {N} -w {w} --seed {seed} --road-file {road_network_path} -d {demand_file} --ind-from {interval[0]} --ind-to {interval[-1]}\"\n",
    "\n",
    "    command_list = ['python', \"worker_mydua.py\"] + options.split(\" \")\n",
    "\n",
    "    script = subprocess.Popen(command_list)#, stdout=subprocess.DEVNULL)\n",
    "    processes.append(script)\n",
    "\n",
    "    \n",
    "print(\"Waiting for all the processes to end...\")\n",
    "for process in processes:\n",
    "    process.wait()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed Time:\", elapsed_time, \"seconds\")   \n",
    "\n",
    "# merging all the chunks\n",
    "\n",
    "list_dict_chunks = [load_dict_from_gzipped_json(result_folder_chunks+d) for d in os.listdir(result_folder_chunks) if \".json\" in d]\n",
    "print(os.listdir(result_folder_chunks))\n",
    "\n",
    "assert len(list_dict_chunks) == njobs\n",
    "merged_dict = {k: v for d in list_dict_chunks for k, v in d.items()}\n",
    "assert len(merged_dict) == N\n",
    "\n",
    "with open(demand_file, 'r') as f:\n",
    "    dict_demand = json.load(f)[\"demand\"]\n",
    "    \n",
    "    \n",
    "# Create the dict for the routed paths\n",
    "\n",
    "dict_routed_paths = {}\n",
    "\n",
    "for vid in dict_demand:\n",
    "    \n",
    "    vid_int_str = vid.split(\"_\")[-1]\n",
    "    \n",
    "    # departure time\n",
    "    dep_time = dict_demand[vid][\"time\"]\n",
    "\n",
    "    # edge list\n",
    "    edge_list = merged_dict[vid_int_str]\n",
    "    \n",
    "    dict_routed_paths[vid] = {\"edges\": edge_list, \"time\":dep_time}\n",
    "    \n",
    "    \n",
    "# SAVE THE ROUTED PATHS\n",
    "if w > 1:\n",
    "    filename_routed_paths = f\"../data/{city}/routed_paths/N{N}/routed_paths_{city}_N{N}_myduaw{w}.rou.xml\"\n",
    "else:\n",
    "    filename_routed_paths = f\"../data/{city}/routed_paths/N{N}/routed_paths_{city}_N{N}_IGfastest.rou.xml\"\n",
    "    \n",
    "if not os.path.exists(f\"../data/{city}/routed_paths/N{N}/\"):\n",
    "    os.makedirs(f\"../data/{city}/routed_paths/N{N}/\", exist_ok=True)\n",
    "\n",
    "create_xml_vehicles(dict_routed_paths, filename_routed_paths, lane_best=True, compress=True, text_comment=f\"Seed {seed}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb825d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4a6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
